{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from os.path import isdir, join, exists\n",
    "from os import mkdir\n",
    "\n",
    "import torch as th\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Literal\n",
    "\n",
    "import random\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_folder = \"/home/samuel/Téléchargements/cmi-detect-behavior-with-sensor-data\"\n",
    "\n",
    "assert isdir(data_folder)\n",
    "\n",
    "output_folder = join(data_folder, \"extracted_tensors\")\n",
    "if not exists(output_folder):\n",
    "    mkdir(output_folder)\n",
    "elif not isdir(output_folder):\n",
    "    raise ValueError(\"Output folder doesn't exist\")\n"
   ],
   "id": "6b9e685a20fe06b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "id_columns = [\n",
    "    \"sequence_id\", \"sequence_counter\"\n",
    "]\n",
    "\n",
    "tof_columns = [\n",
    "    f\"tof_{tof_sensor}_v{tof_pixel}\"\n",
    "    for tof_sensor in range(1, 6)\n",
    "    for tof_pixel in range(64)\n",
    "]\n",
    "\n",
    "acc_columns = [\n",
    "    \"acc_x\",\n",
    "    \"acc_y\",\n",
    "    \"acc_z\",\n",
    "]\n",
    "\n",
    "rot_columns = [\n",
    "    \"rot_w\",\n",
    "    \"rot_x\",\n",
    "    \"rot_y\",\n",
    "    \"rot_z\",\n",
    "]\n",
    "\n",
    "thm_columns = [\n",
    "    \"thm_1\",\n",
    "    \"thm_2\",\n",
    "    \"thm_3\",\n",
    "    \"thm_4\",\n",
    "    \"thm_5\",\n",
    "]\n",
    "\n",
    "other_columns = acc_columns + rot_columns + thm_columns\n",
    "\n",
    "feature_columns = tof_columns + other_columns"
   ],
   "id": "4fbb125301febdf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_dataframe(df: pd.DataFrame, is_test_df: bool = False) -> pd.DataFrame:\n",
    "\n",
    "    for id_col in id_columns:\n",
    "        df[id_col] = df[id_col].astype(str)\n",
    "\n",
    "    print(\"nb features\", len(feature_columns))\n",
    "\n",
    "    # process columns\n",
    "\n",
    "    tof_features_df = df[[\"sequence_id\", \"sequence_counter\"] + tof_columns].copy()\n",
    "    df.drop(tof_columns, axis=1, inplace=True)\n",
    "    for tof_col in tqdm(tof_columns):\n",
    "        tof_features_df[tof_col] = tof_features_df[tof_col].fillna(0).astype(int)\n",
    "\n",
    "    other_features_df = df[[\"sequence_id\", \"sequence_counter\"] + other_columns].copy()\n",
    "    df.drop(other_columns, axis=1, inplace=True)\n",
    "    for other_col in tqdm(other_columns):\n",
    "        other_features_df[other_col] = other_features_df[other_col].fillna(0).astype(int)\n",
    "\n",
    "    grids_series = tof_features_df.progress_apply(\n",
    "        lambda row: [\n",
    "            [\n",
    "                [\n",
    "                    row[f\"tof_{tof_sensor}_v{y * 8 + x}\"]\n",
    "                    for x in range(8)\n",
    "                ] for y in range(8)\n",
    "            ] for tof_sensor in range(1, 6)\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    grids_series.name = \"grids\"\n",
    "    tof_features_df.drop(columns=tof_columns, inplace=True)\n",
    "    tof_features_df = pd.concat([tof_features_df, grids_series], axis=1)\n",
    "\n",
    "    aggregated_other_features_df = (\n",
    "        other_features_df\n",
    "        .sort_values([\"sequence_id\", \"sequence_counter\"])\n",
    "        .groupby(\"sequence_id\")\n",
    "        .agg({\n",
    "            col: list\n",
    "            for col in other_columns\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    aggregated_tof_features_df = (\n",
    "        tof_features_df\n",
    "        .sort_values([\"sequence_id\", \"sequence_counter\"])\n",
    "        .groupby(\"sequence_id\")\n",
    "        .agg({\"grids\": list})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    processed_df = (\n",
    "        aggregated_other_features_df\n",
    "        .merge(aggregated_tof_features_df, on=\"sequence_id\")\n",
    "    )\n",
    "\n",
    "    if not is_test_df:\n",
    "        targets_df = df[[\"sequence_id\", \"sequence_counter\", \"gesture\"]].copy()\n",
    "        targets_df[\"gesture\"] = targets_df[\"gesture\"].astype(str)\n",
    "\n",
    "        aggregated_target_df = (\n",
    "            targets_df.groupby(\"sequence_id\")\n",
    "            .agg({\"gesture\": \"first\"})\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        processed_df = (\n",
    "            processed_df\n",
    "            .merge(aggregated_target_df, on=\"sequence_id\")\n",
    "        )\n",
    "\n",
    "    return processed_df"
   ],
   "id": "2435459cb49bed70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "random.seed(314159)",
   "id": "3a958ea4b9651dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_df = pd.read_csv(join(data_folder, \"train.csv\"), header=0)\n",
    "sequence_ids = list(data_df[\"sequence_id\"].dropna().unique())\n",
    "\n",
    "random.shuffle(sequence_ids)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_sequence_ids = sequence_ids[:int(len(sequence_ids) * train_ratio)]\n",
    "valid_sequence_ids = sequence_ids[int(len(sequence_ids) * train_ratio):]\n",
    "\n",
    "train_df = data_df[data_df[\"sequence_id\"].isin(train_sequence_ids)].copy()\n",
    "valid_df = data_df[data_df[\"sequence_id\"].isin(valid_sequence_ids)].copy()"
   ],
   "id": "e464d8dd7bacebce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_df = pd.read_csv(join(data_folder, \"test.csv\"), header=0)",
   "id": "e2f61e6150675f34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "processed_train_df = process_dataframe(train_df)\n",
    "processed_valid_df = process_dataframe(valid_df)"
   ],
   "id": "1e2c7adacccf1e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "processed_test_df = process_dataframe(test_df, is_test_df=True)",
   "id": "89aaf7b328c676c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_to_tensors(df: pd.DataFrame, curr_class_to_idx: dict[str, int], folder: Literal[\"train\", \"valid\", \"test\"]) -> None:\n",
    "    if not exists(join(output_folder, folder)):\n",
    "        mkdir(join(output_folder, folder))\n",
    "    elif not isdir(join(output_folder, folder)):\n",
    "        raise NotADirectoryError(\"Output folder doesn't exist\")\n",
    "\n",
    "    with open(join(output_folder, folder, \"class_to_idx.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(curr_class_to_idx, f)\n",
    "\n",
    "    for _, row in tqdm(list(df.iterrows())):\n",
    "        sequence_id = row[\"sequence_id\"]\n",
    "\n",
    "\n",
    "        grid = th.clamp_min(th.tensor(row[\"grids\"]), 0).to(th.uint8)\n",
    "        features = th.tensor([row[c] for c in other_columns], dtype=th.float).T\n",
    "\n",
    "\n",
    "        th.save(grid, join(output_folder, folder, f\"{sequence_id}_grids.pth\"))\n",
    "        th.save(features, join(output_folder, folder, f\"{sequence_id}_features.pth\"))\n",
    "\n",
    "        if folder in {\"train\", \"valid\"}:\n",
    "            target = th.tensor([curr_class_to_idx[row[\"gesture\"]]], dtype=th.long)\n",
    "            th.save(target, join(output_folder, folder, f\"{sequence_id}_target.pth\"))\n",
    "        else:\n",
    "            target = th.tensor([0], dtype=th.long)\n",
    "            th.save(target, join(output_folder, folder, f\"{sequence_id}_target.pth\"))"
   ],
   "id": "159f76d4d07e9110",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_classes = list(\n",
    "    set(\n",
    "        list(processed_train_df[\"gesture\"].unique())\n",
    "        + list(processed_valid_df[\"gesture\"].unique())\n",
    "    )\n",
    ")\n",
    "\n",
    "class_to_idx = {\n",
    "    name: i\n",
    "    for i, name in enumerate(sorted(unique_classes))\n",
    "}\n",
    "\n",
    "save_to_tensors(processed_train_df, class_to_idx, folder=\"train\")\n",
    "save_to_tensors(processed_valid_df, class_to_idx, folder=\"valid\")"
   ],
   "id": "46dc414bcf3da971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(join(output_folder, \"train\", \"class_to_idx.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    save_to_tensors(processed_test_df, json.load(f), folder=\"test\")"
   ],
   "id": "2e5ea33cd994e9c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "processed_test_df",
   "id": "e0e3b1bc2400430c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b981ca2976a106b3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
